{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225e8440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with window size 30...\n",
      "Balanced Accuracy (ws=30): 0.5559\n",
      "Model saved to model_ws30.pth\n",
      "\n",
      "Training model with window size 90...\n",
      "Balanced Accuracy (ws=90): 0.6528\n",
      "Model saved to model_ws90.pth\n",
      "\n",
      "Training model with window size 270...\n",
      "Balanced Accuracy (ws=270): 0.8597\n",
      "Model saved to model_ws270.pth\n",
      "\n",
      "Final Balanced Accuracies: {30: 0.5558736918104241, 90: 0.6528314724615961, 270: 0.8596569891267796}\n"
     ]
    }
   ],
   "source": [
    "!pip install -q scikit-learn pandas matplotlib torch joblib\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "\n",
    "# load the data\n",
    "def load_csvs(folder, use_anomaly=True):\n",
    "    files = sorted(glob(folder + '/*.csv'))\n",
    "    all_rows = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep=';')\n",
    "        df.drop(['datetime', 'changepoint'], axis=1, inplace=True, errors='ignore')\n",
    "        if not use_anomaly:\n",
    "            df['anomaly'] = 0\n",
    "        all_rows.append(df)\n",
    "    return pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "base = r'D:\\FinancingSupportSystem\\Group B Data\\Group B Task\\data'\n",
    "df_clean = load_csvs(os.path.join(base, 'anomaly-free'), use_anomaly=False)\n",
    "df_valve1 = load_csvs(os.path.join(base, 'valve1'))\n",
    "df_valve2 = load_csvs(os.path.join(base, 'valve2'))\n",
    "df_other = load_csvs(os.path.join(base, 'other'))\n",
    "\n",
    "df = pd.concat([df_clean, df_valve1, df_valve2, df_other], ignore_index=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Features & labels\n",
    "features = df.drop('anomaly', axis=1).values\n",
    "labels = df['anomaly'].values\n",
    "\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "joblib.dump(scaler, 'scaler.save')  # save scaler for test set\n",
    "\n",
    "\n",
    "# 2. Windowing Function\n",
    "\n",
    "def make_windows(data, labels, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(int(np.any(labels[i:i+window_size])))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Model Definition\n",
    "# ----------------------------\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_size, 8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x).squeeze(-1)\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "\n",
    "# 4. Training + Evaluation Loop\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train_and_evaluate(window_size):\n",
    "    print(f\"\\nTraining model with window size {window_size}...\")\n",
    "    X, y = make_windows(features, labels, window_size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    model = SmallCNN(X.shape[2]).to(device)\n",
    "\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32).transpose(1, 2)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test_t = torch.tensor(X_test, dtype=torch.float32).transpose(1, 2)\n",
    "    y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_t.to(device)).cpu().numpy()\n",
    "    preds = (preds > 0.5).astype(int)\n",
    "    bal_acc = balanced_accuracy_score(y_test, preds)\n",
    "    print(f\"Balanced Accuracy (ws={window_size}): {bal_acc:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    save_path = f\"model_ws{window_size}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    return bal_acc\n",
    "\n",
    "\n",
    "# 5. Train all required models\n",
    "\n",
    "results = {}\n",
    "for ws in [30, 90, 270]:\n",
    "    results[ws] = train_and_evaluate(ws)\n",
    "\n",
    "print(\"\\nFinal Balanced Accuracies:\", results)\n",
    "\n",
    "\n",
    "# 6. bal_acc function\n",
    "\n",
    "def bal_acc(model_path, window_size, X_test, y_test, scaler):\n",
    "    model = SmallCNN(X_test.shape[2])\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X, y = make_windows(X_test, y_test, window_size)\n",
    "    X_test_t = torch.tensor(X, dtype=torch.float32).transpose(1, 2)\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_t).numpy()\n",
    "    preds = (preds > 0.5).astype(int)\n",
    "    return balanced_accuracy_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76707b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
